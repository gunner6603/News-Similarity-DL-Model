{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba11de0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.path.abspath('')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3635f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from utils_ import *\n",
    "from mp_models import *\n",
    "from datasets import *\n",
    "from gensim import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc448a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_doc_list1_path = '../tmp_files/train_val_doc_list1.pkl'\n",
    "train_val_doc_list2_path = '../tmp_files/train_val_doc_list2.pkl'\n",
    "test_doc_list1_path = '../tmp_files/test_doc_list1.pkl'\n",
    "test_doc_list2_path = '../tmp_files/test_doc_list2.pkl'\n",
    "train_label_path = \"../dataset/newssim-train/label.txt\"\n",
    "test_label_path =  \"../dataset/newssim-test/label.txt\"\n",
    "vocab_path = '../tmp_files/vocab.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d6abaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_val_doc_list1_path, 'rb') as f:\n",
    "    train_val_doc_list1 = pickle.load(f)\n",
    "with open(train_val_doc_list2_path, 'rb') as f:\n",
    "    train_val_doc_list2 = pickle.load(f)\n",
    "with open(test_doc_list1_path, 'rb') as f:\n",
    "    test_doc_list1 = pickle.load(f)\n",
    "with open(test_doc_list2_path, 'rb') as f:\n",
    "    test_doc_list2 = pickle.load(f)\n",
    "with open(vocab_path, 'rb') as f:\n",
    "    vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "628be4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_num = 2000\n",
    "np.random.seed(3)\n",
    "indices = np.random.permutation(len(train_val_doc_list1))\n",
    "train_idx = indices[:-val_data_num]\n",
    "val_idx = indices[-val_data_num:]\n",
    "\n",
    "train_doc_list1 = []\n",
    "train_doc_list2 = []\n",
    "val_doc_list1 = []\n",
    "val_doc_list2 = []\n",
    "\n",
    "for idx in train_idx:\n",
    "    train_doc_list1.append(train_val_doc_list1[idx])\n",
    "    train_doc_list2.append(train_val_doc_list2[idx])\n",
    "\n",
    "for idx in val_idx:\n",
    "    val_doc_list1.append(train_val_doc_list1[idx])\n",
    "    val_doc_list2.append(train_val_doc_list2[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2258f7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25627 2000 2000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_doc_list1), len(val_doc_list1), len(test_doc_list1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d06cca90",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = get_labels(train_label_path)[train_idx]\n",
    "val_labels = get_labels(train_label_path)[val_idx]\n",
    "test_labels = get_labels(test_label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e303b65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25627 2000 2000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_labels), len(val_labels), len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f62dcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average document length : 24.78\n",
      "average sentence length : 14.06\n",
      "max document length : 844\n",
      "max sentence length : 204\n"
     ]
    }
   ],
   "source": [
    "max_doc_len = 0\n",
    "max_sent_len = 0\n",
    "total_list_len = 0\n",
    "total_doc_len = 0\n",
    "total_sent_len = 0\n",
    "for doc_list in [train_doc_list1, train_doc_list2, val_doc_list1, val_doc_list2]:\n",
    "    total_list_len += len(doc_list)\n",
    "    for doc in doc_list:\n",
    "        max_doc_len = max(max_doc_len, len(doc))\n",
    "        total_doc_len += len(doc)\n",
    "        for sent in doc:\n",
    "            max_sent_len = max(max_sent_len, len(sent))\n",
    "            total_sent_len += len(sent)\n",
    "print(f'average document length : {total_doc_len/total_list_len:0.2f}\\naverage sentence length : {total_sent_len/total_doc_len:0.2f}')\n",
    "print(f'max document length : {max_doc_len}\\nmax sentence length : {max_sent_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e23e0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_document_length = 26 # dummy variable 26\n",
    "max_sentence_length = 46 # dummy variable 46\n",
    "first_n_words = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df62e2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = NewsDataset(train_doc_list1, train_doc_list2, train_labels, vocab, max_document_length, max_sentence_length, first_n_words)\n",
    "val_data = NewsDataset(val_doc_list1, val_doc_list2, val_labels, vocab, max_document_length, max_sentence_length, first_n_words)\n",
    "test_data = NewsDataset(test_doc_list1, test_doc_list2, test_labels, vocab, max_document_length, max_sentence_length, first_n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7138b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "279f79f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_data_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "test_data_loader = DataLoader(test_data, batch_size=batch_size//4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4eb62d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51053"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8ea9bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embed_dim = 256\n",
    "pad_idx = vocab('<pad>')\n",
    "conv_sizes_inner = [[3,3,8], [3,3,16]]\n",
    "pool_sizes_inner = [[22,22], [5,5]]\n",
    "hidden_dim_inner = 128\n",
    "output_dim_inner = 2\n",
    "conv_sizes_outer = [[3,3,8], [3,3,16]]\n",
    "pool_sizes_outer = [[22,22], [5,5]]\n",
    "hidden_dim_outer = 128\n",
    "learning_rate = 3e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcc655d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nvocab_size = len(vocab)\\nembed_dim = 256\\npad_idx = vocab('<pad>')\\nconv_sizes_inner = [[3,3,8], [3,3,16]]\\npool_sizes_inner = [[22,22], [5,5]]\\nhidden_dim_inner = 128\\noutput_dim_inner = 2\\nconv_sizes_outer = [[3,3,8], [3,3,16]]\\npool_sizes_outer = [[12,12], [5,5]]\\nhidden_dim_outer = 128\\nlearning_rate = 3e-3\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "vocab_size = len(vocab)\n",
    "embed_dim = 256\n",
    "pad_idx = vocab('<pad>')\n",
    "conv_sizes_inner = [[3,3,8], [3,3,16]]\n",
    "pool_sizes_inner = [[22,22], [5,5]]\n",
    "hidden_dim_inner = 128\n",
    "output_dim_inner = 2\n",
    "conv_sizes_outer = [[3,3,8], [3,3,16]]\n",
    "pool_sizes_outer = [[12,12], [5,5]]\n",
    "hidden_dim_outer = 128\n",
    "learning_rate = 3e-3\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffd933ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = DoubleMatchPyramid(vocab_size, embed_dim, pad_idx, conv_sizes_inner, pool_sizes_inner, hidden_dim_inner, output_dim_inner, conv_sizes_outer, pool_sizes_outer, hidden_dim_outer)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afdb58cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): DoubleMatchPyramid(\n",
       "    (embed): Embedding(51053, 256, padding_idx=0)\n",
       "    (mp_inner): MatchPyramid(\n",
       "      (conv): ModuleList(\n",
       "        (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (1): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "      (bn): ModuleList(\n",
       "        (0): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (pool): ModuleList(\n",
       "        (0): AdaptiveAvgPool2d(output_size=(22, 22))\n",
       "        (1): AdaptiveAvgPool2d(output_size=(5, 5))\n",
       "      )\n",
       "      (linear1): Linear(in_features=400, out_features=128, bias=True)\n",
       "      (linear2): Linear(in_features=128, out_features=2, bias=True)\n",
       "    )\n",
       "    (conv): ModuleList(\n",
       "      (0): Conv2d(2, 8, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (bn): ModuleList(\n",
       "      (0): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (pool): ModuleList(\n",
       "      (0): AdaptiveAvgPool2d(output_size=(22, 22))\n",
       "      (1): AdaptiveAvgPool2d(output_size=(5, 5))\n",
       "    )\n",
       "    (linear1): Linear(in_features=400, out_features=128, bias=True)\n",
       "    (linear2): Linear(in_features=128, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.device_count() > 1:\n",
    "    encoder = nn.DataParallel(encoder)\n",
    "encoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec54e968",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss = 10000\n",
    "max_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aac8e699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------TRAIN-----------------------\n",
      "epoch:  1/ 5, batch:  80/801, elapsed_time:    19.8906s\n",
      "epoch:  1/ 5, batch: 160/801, elapsed_time:    36.5904s\n",
      "epoch:  1/ 5, batch: 240/801, elapsed_time:    53.1877s\n",
      "epoch:  1/ 5, batch: 320/801, elapsed_time:    71.4610s\n",
      "epoch:  1/ 5, batch: 400/801, elapsed_time:    87.6430s\n",
      "epoch:  1/ 5, batch: 480/801, elapsed_time:   105.0895s\n",
      "epoch:  1/ 5, batch: 560/801, elapsed_time:   121.1743s\n",
      "epoch:  1/ 5, batch: 640/801, elapsed_time:   138.2565s\n",
      "epoch:  1/ 5, batch: 720/801, elapsed_time:   155.2982s\n",
      "epoch:  1/ 5, batch: 800/801, elapsed_time:   171.9716s\n",
      "epoch:  1/ 5, average_loss_per_batch: 0.4214\n",
      "\n",
      "--------------------VALIDATION--------------------\n",
      "epoch:  1/ 5, batch:  20/63, elapsed_time:   174.2306s\n",
      "epoch:  1/ 5, batch:  40/63, elapsed_time:   176.3227s\n",
      "epoch:  1/ 5, batch:  60/63, elapsed_time:   178.7628s\n",
      "accuracy : 0.8520\n",
      "epoch:  1/ 5, average_loss_per_batch: 0.3459\n",
      "\n",
      "model parameters saved : loss\n",
      "\n",
      "model parameters saved : acc\n",
      "\n",
      "----------------------TRAIN-----------------------\n",
      "epoch:  2/ 5, batch:  80/801, elapsed_time:   196.2111s\n",
      "epoch:  2/ 5, batch: 160/801, elapsed_time:   212.4010s\n",
      "epoch:  2/ 5, batch: 240/801, elapsed_time:   228.9566s\n",
      "epoch:  2/ 5, batch: 320/801, elapsed_time:   245.6355s\n",
      "epoch:  2/ 5, batch: 400/801, elapsed_time:   262.7057s\n",
      "epoch:  2/ 5, batch: 480/801, elapsed_time:   279.7804s\n",
      "epoch:  2/ 5, batch: 560/801, elapsed_time:   296.7412s\n",
      "epoch:  2/ 5, batch: 640/801, elapsed_time:   313.2211s\n",
      "epoch:  2/ 5, batch: 720/801, elapsed_time:   331.3308s\n",
      "epoch:  2/ 5, batch: 800/801, elapsed_time:   347.4866s\n",
      "epoch:  2/ 5, average_loss_per_batch: 0.2783\n",
      "\n",
      "--------------------VALIDATION--------------------\n",
      "epoch:  2/ 5, batch:  20/63, elapsed_time:   349.7220s\n",
      "epoch:  2/ 5, batch:  40/63, elapsed_time:   351.8240s\n",
      "epoch:  2/ 5, batch:  60/63, elapsed_time:   353.9288s\n",
      "accuracy : 0.8530\n",
      "epoch:  2/ 5, average_loss_per_batch: 0.3512\n",
      "\n",
      "model parameters saved : acc\n",
      "\n",
      "----------------------TRAIN-----------------------\n",
      "epoch:  3/ 5, batch:  80/801, elapsed_time:   370.6450s\n",
      "epoch:  3/ 5, batch: 160/801, elapsed_time:   387.1374s\n",
      "epoch:  3/ 5, batch: 240/801, elapsed_time:   404.1331s\n",
      "epoch:  3/ 5, batch: 320/801, elapsed_time:   420.7818s\n",
      "epoch:  3/ 5, batch: 400/801, elapsed_time:   437.5863s\n",
      "epoch:  3/ 5, batch: 480/801, elapsed_time:   454.6554s\n",
      "epoch:  3/ 5, batch: 560/801, elapsed_time:   470.9451s\n",
      "epoch:  3/ 5, batch: 640/801, elapsed_time:   487.1649s\n",
      "epoch:  3/ 5, batch: 720/801, elapsed_time:   503.2350s\n",
      "epoch:  3/ 5, batch: 800/801, elapsed_time:   519.2631s\n",
      "epoch:  3/ 5, average_loss_per_batch: 0.1307\n",
      "\n",
      "--------------------VALIDATION--------------------\n",
      "epoch:  3/ 5, batch:  20/63, elapsed_time:   521.5022s\n",
      "epoch:  3/ 5, batch:  40/63, elapsed_time:   523.6829s\n",
      "epoch:  3/ 5, batch:  60/63, elapsed_time:   525.7798s\n",
      "accuracy : 0.8200\n",
      "epoch:  3/ 5, average_loss_per_batch: 0.4915\n",
      "\n",
      "----------------------TRAIN-----------------------\n",
      "epoch:  4/ 5, batch:  80/801, elapsed_time:   542.6586s\n",
      "epoch:  4/ 5, batch: 160/801, elapsed_time:   559.0331s\n",
      "epoch:  4/ 5, batch: 240/801, elapsed_time:   576.5169s\n",
      "epoch:  4/ 5, batch: 320/801, elapsed_time:   592.9651s\n",
      "epoch:  4/ 5, batch: 400/801, elapsed_time:   609.9207s\n",
      "epoch:  4/ 5, batch: 480/801, elapsed_time:   627.4079s\n",
      "epoch:  4/ 5, batch: 560/801, elapsed_time:   643.4571s\n",
      "epoch:  4/ 5, batch: 640/801, elapsed_time:   659.5772s\n",
      "epoch:  4/ 5, batch: 720/801, elapsed_time:   675.6633s\n",
      "epoch:  4/ 5, batch: 800/801, elapsed_time:   691.7814s\n",
      "epoch:  4/ 5, average_loss_per_batch: 0.0535\n",
      "\n",
      "--------------------VALIDATION--------------------\n",
      "epoch:  4/ 5, batch:  20/63, elapsed_time:   694.0303s\n",
      "epoch:  4/ 5, batch:  40/63, elapsed_time:   696.4342s\n",
      "epoch:  4/ 5, batch:  60/63, elapsed_time:   699.9747s\n",
      "accuracy : 0.8225\n",
      "epoch:  4/ 5, average_loss_per_batch: 0.8723\n",
      "\n",
      "----------------------TRAIN-----------------------\n",
      "epoch:  5/ 5, batch:  80/801, elapsed_time:   716.4716s\n",
      "epoch:  5/ 5, batch: 160/801, elapsed_time:   733.0713s\n",
      "epoch:  5/ 5, batch: 240/801, elapsed_time:   749.3788s\n",
      "epoch:  5/ 5, batch: 320/801, elapsed_time:   765.4753s\n",
      "epoch:  5/ 5, batch: 400/801, elapsed_time:   781.7767s\n",
      "epoch:  5/ 5, batch: 480/801, elapsed_time:   797.9462s\n",
      "epoch:  5/ 5, batch: 560/801, elapsed_time:   814.6257s\n",
      "epoch:  5/ 5, batch: 640/801, elapsed_time:   832.0479s\n",
      "epoch:  5/ 5, batch: 720/801, elapsed_time:   848.4997s\n",
      "epoch:  5/ 5, batch: 800/801, elapsed_time:   866.5113s\n",
      "epoch:  5/ 5, average_loss_per_batch: 0.0296\n",
      "\n",
      "--------------------VALIDATION--------------------\n",
      "epoch:  5/ 5, batch:  20/63, elapsed_time:   869.3362s\n",
      "epoch:  5/ 5, batch:  40/63, elapsed_time:   871.4522s\n",
      "epoch:  5/ 5, batch:  60/63, elapsed_time:   873.5595s\n",
      "accuracy : 0.8115\n",
      "epoch:  5/ 5, average_loss_per_batch: 0.7595\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epoches = 5\n",
    "train_batch_num = len(train_data_loader)\n",
    "val_batch_num = len(val_data_loader)\n",
    "log_step = 80\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epoches):\n",
    "\n",
    "    print(\"{:-^50s}\".format(\"TRAIN\"))\n",
    "    encoder.train()\n",
    "    total_loss = 0\n",
    "    for i, (t1, t2, target) in enumerate(train_data_loader):\n",
    "\n",
    "        t1 = t1.to(device)\n",
    "        t2 = t2.to(device)\n",
    "        target = target.long().to(device)\n",
    "        \n",
    "        out = encoder(t1, t2)\n",
    "        loss = criterion(out, target)\n",
    "        encoder.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if (i+1) % log_step == 0:\n",
    "            print(f'epoch: {epoch+1:2d}/{num_epoches:2d}, batch: {i+1:3d}/{train_batch_num}, elapsed_time: {time.time()-start_time:10.4f}s')\n",
    "\n",
    "    print(f'epoch: {epoch+1:2d}/{num_epoches:2d}, average_loss_per_batch: {total_loss/train_batch_num:5.4f}\\n')\n",
    "\n",
    "    print(\"{:-^50s}\".format(\"VALIDATION\"))\n",
    "    encoder.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        out_list = []\n",
    "        target_list = []\n",
    "        for i, (t1, t2, target) in enumerate(val_data_loader):\n",
    "\n",
    "            t1 = t1.to(device)\n",
    "            t2 = t2.to(device)\n",
    "            target = target.long().to(device)\n",
    "            \n",
    "            out = encoder(t1, t2)\n",
    "            loss = criterion(out, target)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            out_list.append(out.detach().cpu().numpy())\n",
    "            target_list.append(target.detach().cpu().numpy())\n",
    "\n",
    "            if (i+1) % (log_step//4) == 0:\n",
    "                print(f'epoch: {epoch+1:2d}/{num_epoches:2d}, batch: {i+1:3d}/{val_batch_num}, elapsed_time: {time.time()-start_time:10.4f}s')\n",
    "\n",
    "        out = np.concatenate(out_list, axis=0).argmax(1)\n",
    "        target = np.concatenate(target_list, axis=0)\n",
    "        acc = np.sum(out == target) / len(out)\n",
    "        print(f'accuracy : {acc:.4f}')\n",
    "        \n",
    "        print(f'epoch: {epoch+1:2d}/{num_epoches:2d}, average_loss_per_batch: {total_loss/val_batch_num:5.4f}\\n')\n",
    "\n",
    "        if total_loss/val_batch_num < min_loss:\n",
    "            min_loss = total_loss/val_batch_num\n",
    "            torch.save(encoder.state_dict(), './parameters/dmp_loss.pt')\n",
    "            print(\"model parameters saved : loss\\n\")\n",
    "\n",
    "        if acc > max_acc:\n",
    "            max_acc = acc\n",
    "            torch.save(encoder.state_dict(), './parameters/dmp_acc.pt')\n",
    "            print(\"model parameters saved : acc\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dde368ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoder.load_state_dict(torch.load('./parameters/dmp_loss.pt'))\n",
    "# encoder.load_state_dict(torch.load('./parameters/dmp_acc.pt'))\n",
    "encoder.load_state_dict(torch.load('./parameters/dmp_best.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "00fa2d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_list_test = []\n",
    "target_list_test = []\n",
    "encoder.eval()\n",
    "\n",
    "for i, (t1, t2, target) in enumerate(test_data_loader):\n",
    "    \n",
    "    t1 = t1.to(device)\n",
    "    t2 = t2.to(device)\n",
    "    target = target.long().to(device)\n",
    "    \n",
    "    out = encoder(t1, t2)\n",
    "    \n",
    "    out_list_test.append(out.detach().cpu().numpy().argmax(1))\n",
    "    target_list_test.append(target.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "effcb756",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_test = np.concatenate(out_list_test, axis=0)\n",
    "target_test = np.concatenate(target_list_test, axis=0)\n",
    "predictions = out_test\n",
    "labels = target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4db18496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8335\n",
      "precision : 0.7886\n",
      "recall : 0.7753\n",
      "F1 score : 0.7819\n",
      "TP :  597  FN :  173\n",
      "FP :  160  TN : 1070\n"
     ]
    }
   ],
   "source": [
    "print_test_statistics(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd64e54e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

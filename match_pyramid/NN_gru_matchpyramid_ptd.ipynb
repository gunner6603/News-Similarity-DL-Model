{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3306b3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.path.abspath('')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d3635f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from utils_ import *\n",
    "from mp_models import *\n",
    "from datasets import *\n",
    "from gensim import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bc448a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_doc_list1_path = '../tmp_files/train_val_doc_list1.pkl'\n",
    "train_val_doc_list2_path = '../tmp_files/train_val_doc_list2.pkl'\n",
    "test_doc_list1_path = '../tmp_files/test_doc_list1.pkl'\n",
    "test_doc_list2_path = '../tmp_files/test_doc_list2.pkl'\n",
    "train_label_path = \"../dataset/newssim-train/label.txt\"\n",
    "test_label_path =  \"../dataset/newssim-test/label.txt\"\n",
    "vocab_path = '../tmp_files/vocab.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8d6abaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_val_doc_list1_path, 'rb') as f:\n",
    "    train_val_doc_list1 = pickle.load(f)\n",
    "with open(train_val_doc_list2_path, 'rb') as f:\n",
    "    train_val_doc_list2 = pickle.load(f)\n",
    "with open(test_doc_list1_path, 'rb') as f:\n",
    "    test_doc_list1 = pickle.load(f)\n",
    "with open(test_doc_list2_path, 'rb') as f:\n",
    "    test_doc_list2 = pickle.load(f)\n",
    "with open(vocab_path, 'rb') as f:\n",
    "    vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "628be4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_num = 2000\n",
    "np.random.seed(3)\n",
    "indices = np.random.permutation(len(train_val_doc_list1))\n",
    "train_idx = indices[:-val_data_num]\n",
    "val_idx = indices[-val_data_num:]\n",
    "\n",
    "train_doc_list1 = []\n",
    "train_doc_list2 = []\n",
    "val_doc_list1 = []\n",
    "val_doc_list2 = []\n",
    "\n",
    "for idx in train_idx:\n",
    "    train_doc_list1.append(train_val_doc_list1[idx])\n",
    "    train_doc_list2.append(train_val_doc_list2[idx])\n",
    "\n",
    "for idx in val_idx:\n",
    "    val_doc_list1.append(train_val_doc_list1[idx])\n",
    "    val_doc_list2.append(train_val_doc_list2[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2258f7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25627 2000 2000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_doc_list1), len(val_doc_list1), len(test_doc_list1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d06cca90",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = get_labels(train_label_path)[train_idx]\n",
    "val_labels = get_labels(train_label_path)[val_idx]\n",
    "test_labels = get_labels(test_label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e303b65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25627 2000 2000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_labels), len(val_labels), len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4f62dcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average document length : 24.78\n",
      "average sentence length : 14.06\n",
      "max document length : 844\n",
      "max sentence length : 204\n"
     ]
    }
   ],
   "source": [
    "max_doc_len = 0\n",
    "max_sent_len = 0\n",
    "total_list_len = 0\n",
    "total_doc_len = 0\n",
    "total_sent_len = 0\n",
    "for doc_list in [train_doc_list1, train_doc_list2, val_doc_list1, val_doc_list2]:\n",
    "    total_list_len += len(doc_list)\n",
    "    for doc in doc_list:\n",
    "        max_doc_len = max(max_doc_len, len(doc))\n",
    "        total_doc_len += len(doc)\n",
    "        for sent in doc:\n",
    "            max_sent_len = max(max_sent_len, len(sent))\n",
    "            total_sent_len += len(sent)\n",
    "print(f'average document length : {total_doc_len/total_list_len:0.2f}\\naverage sentence length : {total_sent_len/total_doc_len:0.2f}')\n",
    "print(f'max document length : {max_doc_len}\\nmax sentence length : {max_sent_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3e23e0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_document_length = 26\n",
    "max_sentence_length = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "df62e2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = NewsDataset(train_doc_list1, train_doc_list2, train_labels, vocab, max_document_length, max_sentence_length)\n",
    "val_data = NewsDataset(val_doc_list1, val_doc_list2, val_labels, vocab, max_document_length, max_sentence_length)\n",
    "test_data = NewsDataset(test_doc_list1, test_doc_list2, test_labels, vocab, max_document_length, max_sentence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d7138b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "279f79f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_data_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "test_data_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e4eb62d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51053"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a7a251b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embed_dim = 256\n",
    "hidden_dim = 50\n",
    "pad_idx = vocab('<pad>')\n",
    "num_layers_gru = 1\n",
    "conv_sizes = [[3,3,8], [3,3,16]]\n",
    "pool_sizes = [[12,12], [5,5]]\n",
    "mp_hidden_dim = 128\n",
    "learning_rate = 3e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ffd933ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = GMEncoder(vocab_size, embed_dim, hidden_dim, pad_idx, num_layers_gru, conv_sizes, pool_sizes, mp_hidden_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "aa102783",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = models.Word2Vec.load('../tmp_files/word2vec_256d.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "eb3bd7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_word_vectors = np.zeros((vocab_size, embed_dim))\n",
    "for i in range(2, vocab_size):\n",
    "    pretrained_word_vectors[i] = word2vec_model.wv[vocab.idx2word[i]]\n",
    "pretrained_word_vectors_torch = torch.FloatTensor(pretrained_word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a76bbb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.sentence_encoder.embed.weight = nn.Parameter(pretrained_word_vectors_torch)\n",
    "encoder.sentence_encoder.embed.weight.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3ddf1cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): GMEncoder(\n",
       "    (sentence_encoder): SentenceEncoder(\n",
       "      (embed): Embedding(51053, 256, padding_idx=0)\n",
       "      (gru): GRU(256, 50, batch_first=True, bidirectional=True)\n",
       "      (fc): Linear(in_features=100, out_features=100, bias=True)\n",
       "    )\n",
       "    (match_pyramid): MatchPyramid(\n",
       "      (conv): ModuleList(\n",
       "        (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (1): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "      (bn): ModuleList(\n",
       "        (0): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (pool): ModuleList(\n",
       "        (0): AdaptiveAvgPool2d(output_size=(12, 12))\n",
       "        (1): AdaptiveAvgPool2d(output_size=(5, 5))\n",
       "      )\n",
       "      (linear1): Linear(in_features=400, out_features=128, bias=True)\n",
       "      (linear2): Linear(in_features=128, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.device_count() > 1:\n",
    "    encoder = nn.DataParallel(encoder)\n",
    "encoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ec54e968",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss = 10000\n",
    "max_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "aac8e699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------TRAIN-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gunner6603/project1/data/anaconda3/envs/newvenv/lib/python3.9/site-packages/torch/nn/modules/rnn.py:849: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  ../aten/src/ATen/native/cudnn/RNN.cpp:925.)\n",
      "  result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1/ 5, batch:  20/401, elapsed_time:     4.1707s\n",
      "epoch:  1/ 5, batch:  40/401, elapsed_time:     8.0318s\n",
      "epoch:  1/ 5, batch:  60/401, elapsed_time:    11.8049s\n",
      "epoch:  1/ 5, batch:  80/401, elapsed_time:    15.7116s\n",
      "epoch:  1/ 5, batch: 100/401, elapsed_time:    20.0075s\n",
      "epoch:  1/ 5, batch: 120/401, elapsed_time:    23.7206s\n",
      "epoch:  1/ 5, batch: 140/401, elapsed_time:    27.4445s\n",
      "epoch:  1/ 5, batch: 160/401, elapsed_time:    31.1783s\n",
      "epoch:  1/ 5, batch: 180/401, elapsed_time:    35.0445s\n",
      "epoch:  1/ 5, batch: 200/401, elapsed_time:    38.8505s\n",
      "epoch:  1/ 5, batch: 220/401, elapsed_time:    42.5620s\n",
      "epoch:  1/ 5, batch: 240/401, elapsed_time:    46.3150s\n",
      "epoch:  1/ 5, batch: 260/401, elapsed_time:    50.4006s\n",
      "epoch:  1/ 5, batch: 280/401, elapsed_time:    54.6896s\n",
      "epoch:  1/ 5, batch: 300/401, elapsed_time:    58.4371s\n",
      "epoch:  1/ 5, batch: 320/401, elapsed_time:    62.1770s\n",
      "epoch:  1/ 5, batch: 340/401, elapsed_time:    65.9297s\n",
      "epoch:  1/ 5, batch: 360/401, elapsed_time:    69.8785s\n",
      "epoch:  1/ 5, batch: 380/401, elapsed_time:    73.6115s\n",
      "epoch:  1/ 5, batch: 400/401, elapsed_time:    78.1470s\n",
      "epoch:  1/ 5, average_loss_per_batch: 0.4578\n",
      "\n",
      "--------------------VALIDATION--------------------\n",
      "epoch:  1/ 5, batch:   5/32, elapsed_time:    79.0839s\n",
      "epoch:  1/ 5, batch:  10/32, elapsed_time:    80.0794s\n",
      "epoch:  1/ 5, batch:  15/32, elapsed_time:    80.9652s\n",
      "epoch:  1/ 5, batch:  20/32, elapsed_time:    81.8203s\n",
      "epoch:  1/ 5, batch:  25/32, elapsed_time:    82.6363s\n",
      "epoch:  1/ 5, batch:  30/32, elapsed_time:    83.4823s\n",
      "accuracy : 0.8080\n",
      "epoch:  1/ 5, average_loss_per_batch: 0.4293\n",
      "\n",
      "model parameters saved : loss\n",
      "\n",
      "model parameters saved : acc\n",
      "\n",
      "----------------------TRAIN-----------------------\n",
      "epoch:  2/ 5, batch:  20/401, elapsed_time:    87.7016s\n",
      "epoch:  2/ 5, batch:  40/401, elapsed_time:    91.4359s\n",
      "epoch:  2/ 5, batch:  60/401, elapsed_time:    95.1722s\n",
      "epoch:  2/ 5, batch:  80/401, elapsed_time:    98.8804s\n",
      "epoch:  2/ 5, batch: 100/401, elapsed_time:   102.9911s\n",
      "epoch:  2/ 5, batch: 120/401, elapsed_time:   107.3662s\n",
      "epoch:  2/ 5, batch: 140/401, elapsed_time:   111.7524s\n",
      "epoch:  2/ 5, batch: 160/401, elapsed_time:   115.8529s\n",
      "epoch:  2/ 5, batch: 180/401, elapsed_time:   119.9460s\n",
      "epoch:  2/ 5, batch: 200/401, elapsed_time:   124.3979s\n",
      "epoch:  2/ 5, batch: 220/401, elapsed_time:   128.4521s\n",
      "epoch:  2/ 5, batch: 240/401, elapsed_time:   132.4171s\n",
      "epoch:  2/ 5, batch: 260/401, elapsed_time:   136.8060s\n",
      "epoch:  2/ 5, batch: 280/401, elapsed_time:   141.3363s\n",
      "epoch:  2/ 5, batch: 300/401, elapsed_time:   145.1669s\n",
      "epoch:  2/ 5, batch: 320/401, elapsed_time:   149.0103s\n",
      "epoch:  2/ 5, batch: 340/401, elapsed_time:   153.2724s\n",
      "epoch:  2/ 5, batch: 360/401, elapsed_time:   157.8694s\n",
      "epoch:  2/ 5, batch: 380/401, elapsed_time:   161.5550s\n",
      "epoch:  2/ 5, batch: 400/401, elapsed_time:   165.3149s\n",
      "epoch:  2/ 5, average_loss_per_batch: 0.3545\n",
      "\n",
      "--------------------VALIDATION--------------------\n",
      "epoch:  2/ 5, batch:   5/32, elapsed_time:   166.2566s\n",
      "epoch:  2/ 5, batch:  10/32, elapsed_time:   167.0834s\n",
      "epoch:  2/ 5, batch:  15/32, elapsed_time:   167.9131s\n",
      "epoch:  2/ 5, batch:  20/32, elapsed_time:   168.7604s\n",
      "epoch:  2/ 5, batch:  25/32, elapsed_time:   169.5946s\n",
      "epoch:  2/ 5, batch:  30/32, elapsed_time:   170.4344s\n",
      "accuracy : 0.8380\n",
      "epoch:  2/ 5, average_loss_per_batch: 0.3682\n",
      "\n",
      "model parameters saved : loss\n",
      "\n",
      "model parameters saved : acc\n",
      "\n",
      "----------------------TRAIN-----------------------\n",
      "epoch:  3/ 5, batch:  20/401, elapsed_time:   174.6167s\n",
      "epoch:  3/ 5, batch:  40/401, elapsed_time:   178.6801s\n",
      "epoch:  3/ 5, batch:  60/401, elapsed_time:   183.2186s\n",
      "epoch:  3/ 5, batch:  80/401, elapsed_time:   186.9500s\n",
      "epoch:  3/ 5, batch: 100/401, elapsed_time:   191.7381s\n",
      "epoch:  3/ 5, batch: 120/401, elapsed_time:   195.5283s\n",
      "epoch:  3/ 5, batch: 140/401, elapsed_time:   199.2552s\n",
      "epoch:  3/ 5, batch: 160/401, elapsed_time:   203.0044s\n",
      "epoch:  3/ 5, batch: 180/401, elapsed_time:   206.6664s\n",
      "epoch:  3/ 5, batch: 200/401, elapsed_time:   210.3851s\n",
      "epoch:  3/ 5, batch: 220/401, elapsed_time:   214.2038s\n",
      "epoch:  3/ 5, batch: 240/401, elapsed_time:   218.8737s\n",
      "epoch:  3/ 5, batch: 260/401, elapsed_time:   222.7684s\n",
      "epoch:  3/ 5, batch: 280/401, elapsed_time:   226.5978s\n",
      "epoch:  3/ 5, batch: 300/401, elapsed_time:   230.2957s\n",
      "epoch:  3/ 5, batch: 320/401, elapsed_time:   234.5109s\n",
      "epoch:  3/ 5, batch: 340/401, elapsed_time:   238.4420s\n",
      "epoch:  3/ 5, batch: 360/401, elapsed_time:   242.7379s\n",
      "epoch:  3/ 5, batch: 380/401, elapsed_time:   246.4816s\n",
      "epoch:  3/ 5, batch: 400/401, elapsed_time:   250.4652s\n",
      "epoch:  3/ 5, average_loss_per_batch: 0.3086\n",
      "\n",
      "--------------------VALIDATION--------------------\n",
      "epoch:  3/ 5, batch:   5/32, elapsed_time:   251.5245s\n",
      "epoch:  3/ 5, batch:  10/32, elapsed_time:   252.3557s\n",
      "epoch:  3/ 5, batch:  15/32, elapsed_time:   253.1860s\n",
      "epoch:  3/ 5, batch:  20/32, elapsed_time:   254.0412s\n",
      "epoch:  3/ 5, batch:  25/32, elapsed_time:   254.8585s\n",
      "epoch:  3/ 5, batch:  30/32, elapsed_time:   255.6931s\n",
      "accuracy : 0.8520\n",
      "epoch:  3/ 5, average_loss_per_batch: 0.3536\n",
      "\n",
      "model parameters saved : loss\n",
      "\n",
      "model parameters saved : acc\n",
      "\n",
      "----------------------TRAIN-----------------------\n",
      "epoch:  4/ 5, batch:  20/401, elapsed_time:   260.9814s\n",
      "epoch:  4/ 5, batch:  40/401, elapsed_time:   265.0677s\n",
      "epoch:  4/ 5, batch:  60/401, elapsed_time:   268.8187s\n",
      "epoch:  4/ 5, batch:  80/401, elapsed_time:   272.5189s\n",
      "epoch:  4/ 5, batch: 100/401, elapsed_time:   276.3867s\n",
      "epoch:  4/ 5, batch: 120/401, elapsed_time:   280.1500s\n",
      "epoch:  4/ 5, batch: 140/401, elapsed_time:   283.9283s\n",
      "epoch:  4/ 5, batch: 160/401, elapsed_time:   288.6981s\n",
      "epoch:  4/ 5, batch: 180/401, elapsed_time:   292.3618s\n",
      "epoch:  4/ 5, batch: 200/401, elapsed_time:   296.5619s\n",
      "epoch:  4/ 5, batch: 220/401, elapsed_time:   300.4400s\n",
      "epoch:  4/ 5, batch: 240/401, elapsed_time:   305.0554s\n",
      "epoch:  4/ 5, batch: 260/401, elapsed_time:   309.7977s\n",
      "epoch:  4/ 5, batch: 280/401, elapsed_time:   314.4040s\n",
      "epoch:  4/ 5, batch: 300/401, elapsed_time:   318.3389s\n",
      "epoch:  4/ 5, batch: 320/401, elapsed_time:   322.3266s\n",
      "epoch:  4/ 5, batch: 340/401, elapsed_time:   326.9342s\n",
      "epoch:  4/ 5, batch: 360/401, elapsed_time:   331.0120s\n",
      "epoch:  4/ 5, batch: 380/401, elapsed_time:   334.9409s\n",
      "epoch:  4/ 5, batch: 400/401, elapsed_time:   339.6154s\n",
      "epoch:  4/ 5, average_loss_per_batch: 0.2749\n",
      "\n",
      "--------------------VALIDATION--------------------\n",
      "epoch:  4/ 5, batch:   5/32, elapsed_time:   341.4486s\n",
      "epoch:  4/ 5, batch:  10/32, elapsed_time:   342.2962s\n",
      "epoch:  4/ 5, batch:  15/32, elapsed_time:   343.1332s\n",
      "epoch:  4/ 5, batch:  20/32, elapsed_time:   343.9837s\n",
      "epoch:  4/ 5, batch:  25/32, elapsed_time:   344.8072s\n",
      "epoch:  4/ 5, batch:  30/32, elapsed_time:   345.6434s\n",
      "accuracy : 0.8385\n",
      "epoch:  4/ 5, average_loss_per_batch: 0.3720\n",
      "\n",
      "----------------------TRAIN-----------------------\n",
      "epoch:  5/ 5, batch:  20/401, elapsed_time:   349.8086s\n",
      "epoch:  5/ 5, batch:  40/401, elapsed_time:   353.7925s\n",
      "epoch:  5/ 5, batch:  60/401, elapsed_time:   357.4997s\n",
      "epoch:  5/ 5, batch:  80/401, elapsed_time:   361.2226s\n",
      "epoch:  5/ 5, batch: 100/401, elapsed_time:   365.2208s\n",
      "epoch:  5/ 5, batch: 120/401, elapsed_time:   369.7968s\n",
      "epoch:  5/ 5, batch: 140/401, elapsed_time:   375.7806s\n",
      "epoch:  5/ 5, batch: 160/401, elapsed_time:   379.4832s\n",
      "epoch:  5/ 5, batch: 180/401, elapsed_time:   383.7304s\n",
      "epoch:  5/ 5, batch: 200/401, elapsed_time:   388.1068s\n",
      "epoch:  5/ 5, batch: 220/401, elapsed_time:   392.3880s\n",
      "epoch:  5/ 5, batch: 240/401, elapsed_time:   397.2959s\n",
      "epoch:  5/ 5, batch: 260/401, elapsed_time:   402.3952s\n",
      "epoch:  5/ 5, batch: 280/401, elapsed_time:   406.1787s\n",
      "epoch:  5/ 5, batch: 300/401, elapsed_time:   409.9077s\n",
      "epoch:  5/ 5, batch: 320/401, elapsed_time:   413.9864s\n",
      "epoch:  5/ 5, batch: 340/401, elapsed_time:   417.6968s\n",
      "epoch:  5/ 5, batch: 360/401, elapsed_time:   421.6163s\n",
      "epoch:  5/ 5, batch: 380/401, elapsed_time:   426.0594s\n",
      "epoch:  5/ 5, batch: 400/401, elapsed_time:   430.0728s\n",
      "epoch:  5/ 5, average_loss_per_batch: 0.2461\n",
      "\n",
      "--------------------VALIDATION--------------------\n",
      "epoch:  5/ 5, batch:   5/32, elapsed_time:   431.5748s\n",
      "epoch:  5/ 5, batch:  10/32, elapsed_time:   432.7388s\n",
      "epoch:  5/ 5, batch:  15/32, elapsed_time:   433.5668s\n",
      "epoch:  5/ 5, batch:  20/32, elapsed_time:   434.4235s\n",
      "epoch:  5/ 5, batch:  25/32, elapsed_time:   435.2448s\n",
      "epoch:  5/ 5, batch:  30/32, elapsed_time:   436.0938s\n",
      "accuracy : 0.8465\n",
      "epoch:  5/ 5, average_loss_per_batch: 0.3835\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epoches = 5\n",
    "train_batch_num = len(train_data_loader)\n",
    "val_batch_num = len(val_data_loader)\n",
    "log_step = 200\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epoches):\n",
    "\n",
    "    print(\"{:-^50s}\".format(\"TRAIN\"))\n",
    "    encoder.train()\n",
    "    total_loss = 0\n",
    "    for i, (t1, t2, target) in enumerate(train_data_loader):\n",
    "\n",
    "        t1 = t1.to(device)\n",
    "        t2 = t2.to(device)\n",
    "        target = target.long().to(device)\n",
    "        \n",
    "        out = encoder(t1, t2)\n",
    "        loss = criterion(out, target)\n",
    "        encoder.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if (i+1) % log_step == 0:\n",
    "            print(f'epoch: {epoch+1:2d}/{num_epoches:2d}, batch: {i+1:3d}/{train_batch_num}, elapsed_time: {time.time()-start_time:10.4f}s')\n",
    "\n",
    "    print(f'epoch: {epoch+1:2d}/{num_epoches:2d}, average_loss_per_batch: {total_loss/train_batch_num:5.4f}\\n')\n",
    "\n",
    "    print(\"{:-^50s}\".format(\"VALIDATION\"))\n",
    "    encoder.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        out_list = []\n",
    "        target_list = []\n",
    "        for i, (t1, t2, target) in enumerate(val_data_loader):\n",
    "            \n",
    "            t1 = t1.to(device)\n",
    "            t2 = t2.to(device)\n",
    "            target = target.long().to(device)\n",
    "            \n",
    "            out = encoder(t1, t2)\n",
    "            loss = criterion(out, target)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            out_list.append(out.detach().cpu().numpy())\n",
    "            target_list.append(target.detach().cpu().numpy())\n",
    "\n",
    "            if (i+1) % (log_step//4) == 0:\n",
    "                print(f'epoch: {epoch+1:2d}/{num_epoches:2d}, batch: {i+1:3d}/{val_batch_num}, elapsed_time: {time.time()-start_time:10.4f}s')\n",
    "\n",
    "        out = np.concatenate(out_list, axis=0).argmax(1)\n",
    "        target = np.concatenate(target_list, axis=0)\n",
    "        acc = np.sum(out == target) / len(out)\n",
    "        print(f'accuracy : {acc:.4f}')\n",
    "        \n",
    "        print(f'epoch: {epoch+1:2d}/{num_epoches:2d}, average_loss_per_batch: {total_loss/val_batch_num:5.4f}\\n')\n",
    "\n",
    "        if total_loss/val_batch_num < min_loss:\n",
    "            min_loss = total_loss/val_batch_num\n",
    "            torch.save(encoder.state_dict(), './parameters/gru_mp_ptd_loss.pt')\n",
    "            print(\"model parameters saved : loss\\n\")\n",
    "\n",
    "        if acc > max_acc:\n",
    "            max_acc = acc\n",
    "            torch.save(encoder.state_dict(), './parameters/gru_mp_ptd_acc.pt')\n",
    "            print(\"model parameters saved : acc\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "dde368ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoder.load_state_dict(torch.load('./parameters/gru_mp_ptd_loss.pt'))\n",
    "# encoder.load_state_dict(torch.load('./parameters/gru_mp_ptd_acc.pt'))\n",
    "# encoder.load_state_dict(torch.load('./parameters/gru_mp_ptd_best.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f8b0fe3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): GMEncoder(\n",
       "    (sentence_encoder): SentenceEncoder(\n",
       "      (embed): Embedding(51053, 256, padding_idx=0)\n",
       "      (gru): GRU(256, 50, batch_first=True, bidirectional=True)\n",
       "      (fc): Linear(in_features=100, out_features=100, bias=True)\n",
       "    )\n",
       "    (match_pyramid): MatchPyramid(\n",
       "      (conv): ModuleList(\n",
       "        (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (1): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "      (bn): ModuleList(\n",
       "        (0): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (pool): ModuleList(\n",
       "        (0): AdaptiveAvgPool2d(output_size=(12, 12))\n",
       "        (1): AdaptiveAvgPool2d(output_size=(5, 5))\n",
       "      )\n",
       "      (linear1): Linear(in_features=400, out_features=128, bias=True)\n",
       "      (linear2): Linear(in_features=128, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = GMEncoder(vocab_size, embed_dim, hidden_dim, pad_idx, num_layers_gru, conv_sizes, pool_sizes, mp_hidden_dim)\n",
    "encoder.load_state_dict(torch.load('./parameters/gru_mp_ptd_best.pt'))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.device_count() > 1:\n",
    "    encoder = nn.DataParallel(encoder)\n",
    "encoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "00fa2d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_list_test = []\n",
    "target_list_test = []\n",
    "encoder.eval()\n",
    "\n",
    "for i, (t1, t2, target) in enumerate(test_data_loader):\n",
    "\n",
    "    t1 = t1.to(device)\n",
    "    t2 = t2.to(device)\n",
    "    target = target.long().to(device)\n",
    "    \n",
    "    out = encoder(t1, t2)\n",
    "    \n",
    "    out_list_test.append(out.detach().cpu().numpy().argmax(1))\n",
    "    target_list_test.append(target.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "effcb756",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_test = np.concatenate(out_list_test, axis=0)\n",
    "target_test = np.concatenate(target_list_test, axis=0)\n",
    "predictions = out_test\n",
    "labels = target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4db18496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8330\n",
      "precision : 0.7868\n",
      "recall : 0.7766\n",
      "F1 score : 0.7817\n",
      "TP :  598  FN :  172\n",
      "FP :  162  TN : 1068\n"
     ]
    }
   ],
   "source": [
    "print_test_statistics(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b45070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a51d662",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

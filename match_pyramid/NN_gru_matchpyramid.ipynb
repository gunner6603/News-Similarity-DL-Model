{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3306b3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.path.abspath('')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3635f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from utils_ import *\n",
    "from mp_models import *\n",
    "from datasets import *\n",
    "from gensim import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc448a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_doc_list1_path = '../tmp_files/train_val_doc_list1.pkl'\n",
    "train_val_doc_list2_path = '../tmp_files/train_val_doc_list2.pkl'\n",
    "test_doc_list1_path = '../tmp_files/test_doc_list1.pkl'\n",
    "test_doc_list2_path = '../tmp_files/test_doc_list2.pkl'\n",
    "train_label_path = \"../dataset/newssim-train/label.txt\"\n",
    "test_label_path =  \"../dataset/newssim-test/label.txt\"\n",
    "vocab_path = '../tmp_files/vocab.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d6abaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_val_doc_list1_path, 'rb') as f:\n",
    "    train_val_doc_list1 = pickle.load(f)\n",
    "with open(train_val_doc_list2_path, 'rb') as f:\n",
    "    train_val_doc_list2 = pickle.load(f)\n",
    "with open(test_doc_list1_path, 'rb') as f:\n",
    "    test_doc_list1 = pickle.load(f)\n",
    "with open(test_doc_list2_path, 'rb') as f:\n",
    "    test_doc_list2 = pickle.load(f)\n",
    "with open(vocab_path, 'rb') as f:\n",
    "    vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "628be4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_num = 2000\n",
    "np.random.seed(3)\n",
    "indices = np.random.permutation(len(train_val_doc_list1))\n",
    "train_idx = indices[:-val_data_num]\n",
    "val_idx = indices[-val_data_num:]\n",
    "\n",
    "train_doc_list1 = []\n",
    "train_doc_list2 = []\n",
    "val_doc_list1 = []\n",
    "val_doc_list2 = []\n",
    "\n",
    "for idx in train_idx:\n",
    "    train_doc_list1.append(train_val_doc_list1[idx])\n",
    "    train_doc_list2.append(train_val_doc_list2[idx])\n",
    "\n",
    "for idx in val_idx:\n",
    "    val_doc_list1.append(train_val_doc_list1[idx])\n",
    "    val_doc_list2.append(train_val_doc_list2[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2258f7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25627 2000 2000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_doc_list1), len(val_doc_list1), len(test_doc_list1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d06cca90",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = get_labels(train_label_path)[train_idx]\n",
    "val_labels = get_labels(train_label_path)[val_idx]\n",
    "test_labels = get_labels(test_label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e303b65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25627 2000 2000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_labels), len(val_labels), len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f62dcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average document length : 24.78\n",
      "average sentence length : 14.06\n",
      "max document length : 844\n",
      "max sentence length : 204\n"
     ]
    }
   ],
   "source": [
    "max_doc_len = 0\n",
    "max_sent_len = 0\n",
    "total_list_len = 0\n",
    "total_doc_len = 0\n",
    "total_sent_len = 0\n",
    "for doc_list in [train_doc_list1, train_doc_list2, val_doc_list1, val_doc_list2]:\n",
    "    total_list_len += len(doc_list)\n",
    "    for doc in doc_list:\n",
    "        max_doc_len = max(max_doc_len, len(doc))\n",
    "        total_doc_len += len(doc)\n",
    "        for sent in doc:\n",
    "            max_sent_len = max(max_sent_len, len(sent))\n",
    "            total_sent_len += len(sent)\n",
    "print(f'average document length : {total_doc_len/total_list_len:0.2f}\\naverage sentence length : {total_sent_len/total_doc_len:0.2f}')\n",
    "print(f'max document length : {max_doc_len}\\nmax sentence length : {max_sent_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e23e0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_document_length = 26\n",
    "max_sentence_length = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df62e2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = NewsDataset(train_doc_list1, train_doc_list2, train_labels, vocab, max_document_length, max_sentence_length)\n",
    "val_data = NewsDataset(val_doc_list1, val_doc_list2, val_labels, vocab, max_document_length, max_sentence_length)\n",
    "test_data = NewsDataset(test_doc_list1, test_doc_list2, test_labels, vocab, max_document_length, max_sentence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7138b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "279f79f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_data_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "test_data_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4eb62d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51053"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7a251b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embed_dim = 256\n",
    "hidden_dim = 50\n",
    "pad_idx = vocab('<pad>')\n",
    "num_layers_gru = 1\n",
    "conv_sizes = [[3,3,8], [3,3,16]]\n",
    "pool_sizes = [[12,12], [5,5]]\n",
    "mp_hidden_dim = 128\n",
    "learning_rate = 3e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffd933ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = GMEncoder(vocab_size, embed_dim, hidden_dim, pad_idx, num_layers_gru, conv_sizes, pool_sizes, mp_hidden_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a96dbbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = models.Word2Vec.load('../tmp_files/word2vec_256d.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba4b684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_word_vectors = np.zeros((vocab_size, embed_dim))\n",
    "for i in range(2, vocab_size):\n",
    "    pretrained_word_vectors[i] = word2vec_model.wv[vocab.idx2word[i]]\n",
    "pretrained_word_vectors_torch = torch.FloatTensor(pretrained_word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0669ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.sentence_encoder.embed.weight = nn.Parameter(pretrained_word_vectors_torch)\n",
    "encoder.sentence_encoder.embed.weight.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ddec8c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): GMEncoder(\n",
       "    (sentence_encoder): SentenceEncoder(\n",
       "      (embed): Embedding(51053, 256, padding_idx=0)\n",
       "      (gru): GRU(256, 50, batch_first=True, bidirectional=True)\n",
       "      (fc): Linear(in_features=100, out_features=100, bias=True)\n",
       "    )\n",
       "    (match_pyramid): MatchPyramid(\n",
       "      (conv): ModuleList(\n",
       "        (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (1): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "      (bn): ModuleList(\n",
       "        (0): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (pool): ModuleList(\n",
       "        (0): AdaptiveAvgPool2d(output_size=(12, 12))\n",
       "        (1): AdaptiveAvgPool2d(output_size=(5, 5))\n",
       "      )\n",
       "      (linear1): Linear(in_features=400, out_features=128, bias=True)\n",
       "      (linear2): Linear(in_features=128, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.device_count() > 1:\n",
    "    encoder = nn.DataParallel(encoder)\n",
    "encoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec54e968",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss = 10000\n",
    "max_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aac8e699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------TRAIN-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gunner6603/project1/data/anaconda3/envs/newvenv/lib/python3.9/site-packages/torch/nn/modules/rnn.py:849: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  ../aten/src/ATen/native/cudnn/RNN.cpp:925.)\n",
      "  result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1/ 5, batch:  20/401, elapsed_time:     3.8316s\n",
      "epoch:  1/ 5, batch:  40/401, elapsed_time:     8.1731s\n",
      "epoch:  1/ 5, batch:  60/401, elapsed_time:    11.8773s\n",
      "epoch:  1/ 5, batch:  80/401, elapsed_time:    15.6530s\n",
      "epoch:  1/ 5, batch: 100/401, elapsed_time:    19.8966s\n",
      "epoch:  1/ 5, batch: 120/401, elapsed_time:    23.5789s\n",
      "epoch:  1/ 5, batch: 140/401, elapsed_time:    27.2377s\n",
      "epoch:  1/ 5, batch: 160/401, elapsed_time:    30.9843s\n",
      "epoch:  1/ 5, batch: 180/401, elapsed_time:    34.9407s\n",
      "epoch:  1/ 5, batch: 200/401, elapsed_time:    39.4867s\n",
      "epoch:  1/ 5, batch: 220/401, elapsed_time:    43.3909s\n",
      "epoch:  1/ 5, batch: 240/401, elapsed_time:    47.6061s\n",
      "epoch:  1/ 5, batch: 260/401, elapsed_time:    51.6923s\n",
      "epoch:  1/ 5, batch: 280/401, elapsed_time:    55.3640s\n",
      "epoch:  1/ 5, batch: 300/401, elapsed_time:    59.0614s\n",
      "epoch:  1/ 5, batch: 320/401, elapsed_time:    62.7220s\n",
      "epoch:  1/ 5, batch: 340/401, elapsed_time:    66.6295s\n",
      "epoch:  1/ 5, batch: 360/401, elapsed_time:    70.3028s\n",
      "epoch:  1/ 5, batch: 380/401, elapsed_time:    73.9642s\n",
      "epoch:  1/ 5, batch: 400/401, elapsed_time:    77.6484s\n",
      "epoch:  1/ 5, average_loss_per_batch: 0.4710\n",
      "\n",
      "--------------------VALIDATION--------------------\n",
      "epoch:  1/ 5, batch:   5/32, elapsed_time:    78.9110s\n",
      "epoch:  1/ 5, batch:  10/32, elapsed_time:    80.2876s\n",
      "epoch:  1/ 5, batch:  15/32, elapsed_time:    81.6697s\n",
      "epoch:  1/ 5, batch:  20/32, elapsed_time:    83.0795s\n",
      "epoch:  1/ 5, batch:  25/32, elapsed_time:    84.4406s\n",
      "epoch:  1/ 5, batch:  30/32, elapsed_time:    85.8366s\n",
      "accuracy : 0.8140\n",
      "epoch:  1/ 5, average_loss_per_batch: 0.3851\n",
      "\n",
      "model parameters saved : loss\n",
      "\n",
      "model parameters saved : acc\n",
      "\n",
      "----------------------TRAIN-----------------------\n",
      "epoch:  2/ 5, batch:  20/401, elapsed_time:    90.6266s\n",
      "epoch:  2/ 5, batch:  40/401, elapsed_time:    95.1076s\n",
      "epoch:  2/ 5, batch:  60/401, elapsed_time:    98.7973s\n",
      "epoch:  2/ 5, batch:  80/401, elapsed_time:   102.8674s\n",
      "epoch:  2/ 5, batch: 100/401, elapsed_time:   107.3728s\n",
      "epoch:  2/ 5, batch: 120/401, elapsed_time:   112.8748s\n",
      "epoch:  2/ 5, batch: 140/401, elapsed_time:   116.5862s\n",
      "epoch:  2/ 5, batch: 160/401, elapsed_time:   120.2780s\n",
      "epoch:  2/ 5, batch: 180/401, elapsed_time:   123.9530s\n",
      "epoch:  2/ 5, batch: 200/401, elapsed_time:   127.6189s\n",
      "epoch:  2/ 5, batch: 220/401, elapsed_time:   131.2762s\n",
      "epoch:  2/ 5, batch: 240/401, elapsed_time:   135.1531s\n",
      "epoch:  2/ 5, batch: 260/401, elapsed_time:   139.5085s\n",
      "epoch:  2/ 5, batch: 280/401, elapsed_time:   143.2988s\n",
      "epoch:  2/ 5, batch: 300/401, elapsed_time:   146.9984s\n",
      "epoch:  2/ 5, batch: 320/401, elapsed_time:   151.5139s\n",
      "epoch:  2/ 5, batch: 340/401, elapsed_time:   156.0701s\n",
      "epoch:  2/ 5, batch: 360/401, elapsed_time:   159.9606s\n",
      "epoch:  2/ 5, batch: 380/401, elapsed_time:   164.2574s\n",
      "epoch:  2/ 5, batch: 400/401, elapsed_time:   167.9543s\n",
      "epoch:  2/ 5, average_loss_per_batch: 0.3549\n",
      "\n",
      "--------------------VALIDATION--------------------\n",
      "epoch:  2/ 5, batch:   5/32, elapsed_time:   168.8761s\n",
      "epoch:  2/ 5, batch:  10/32, elapsed_time:   169.6914s\n",
      "epoch:  2/ 5, batch:  15/32, elapsed_time:   170.5156s\n",
      "epoch:  2/ 5, batch:  20/32, elapsed_time:   171.3608s\n",
      "epoch:  2/ 5, batch:  25/32, elapsed_time:   172.1649s\n",
      "epoch:  2/ 5, batch:  30/32, elapsed_time:   172.9952s\n",
      "accuracy : 0.8360\n",
      "epoch:  2/ 5, average_loss_per_batch: 0.3775\n",
      "\n",
      "model parameters saved : loss\n",
      "\n",
      "model parameters saved : acc\n",
      "\n",
      "----------------------TRAIN-----------------------\n",
      "epoch:  3/ 5, batch:  20/401, elapsed_time:   177.1102s\n",
      "epoch:  3/ 5, batch:  40/401, elapsed_time:   180.7697s\n",
      "epoch:  3/ 5, batch:  60/401, elapsed_time:   184.4273s\n",
      "epoch:  3/ 5, batch:  80/401, elapsed_time:   188.0936s\n",
      "epoch:  3/ 5, batch: 100/401, elapsed_time:   191.9928s\n",
      "epoch:  3/ 5, batch: 120/401, elapsed_time:   195.6572s\n",
      "epoch:  3/ 5, batch: 140/401, elapsed_time:   199.8998s\n",
      "epoch:  3/ 5, batch: 160/401, elapsed_time:   203.6352s\n",
      "epoch:  3/ 5, batch: 180/401, elapsed_time:   207.3424s\n",
      "epoch:  3/ 5, batch: 200/401, elapsed_time:   211.0134s\n",
      "epoch:  3/ 5, batch: 220/401, elapsed_time:   214.6682s\n",
      "epoch:  3/ 5, batch: 240/401, elapsed_time:   218.8806s\n",
      "epoch:  3/ 5, batch: 260/401, elapsed_time:   222.6862s\n",
      "epoch:  3/ 5, batch: 280/401, elapsed_time:   226.5586s\n",
      "epoch:  3/ 5, batch: 300/401, elapsed_time:   230.9851s\n",
      "epoch:  3/ 5, batch: 320/401, elapsed_time:   234.6566s\n",
      "epoch:  3/ 5, batch: 340/401, elapsed_time:   238.7454s\n",
      "epoch:  3/ 5, batch: 360/401, elapsed_time:   242.4453s\n",
      "epoch:  3/ 5, batch: 380/401, elapsed_time:   246.2226s\n",
      "epoch:  3/ 5, batch: 400/401, elapsed_time:   249.9322s\n",
      "epoch:  3/ 5, average_loss_per_batch: 0.3090\n",
      "\n",
      "--------------------VALIDATION--------------------\n",
      "epoch:  3/ 5, batch:   5/32, elapsed_time:   250.8489s\n",
      "epoch:  3/ 5, batch:  10/32, elapsed_time:   251.6635s\n",
      "epoch:  3/ 5, batch:  15/32, elapsed_time:   252.4794s\n",
      "epoch:  3/ 5, batch:  20/32, elapsed_time:   253.5172s\n",
      "epoch:  3/ 5, batch:  25/32, elapsed_time:   254.4085s\n",
      "epoch:  3/ 5, batch:  30/32, elapsed_time:   255.2324s\n",
      "accuracy : 0.8390\n",
      "epoch:  3/ 5, average_loss_per_batch: 0.3573\n",
      "\n",
      "model parameters saved : loss\n",
      "\n",
      "model parameters saved : acc\n",
      "\n",
      "----------------------TRAIN-----------------------\n",
      "epoch:  4/ 5, batch:  20/401, elapsed_time:   259.3601s\n",
      "epoch:  4/ 5, batch:  40/401, elapsed_time:   263.4901s\n",
      "epoch:  4/ 5, batch:  60/401, elapsed_time:   267.3140s\n",
      "epoch:  4/ 5, batch:  80/401, elapsed_time:   271.0030s\n",
      "epoch:  4/ 5, batch: 100/401, elapsed_time:   274.6930s\n",
      "epoch:  4/ 5, batch: 120/401, elapsed_time:   278.3655s\n",
      "epoch:  4/ 5, batch: 140/401, elapsed_time:   282.0784s\n",
      "epoch:  4/ 5, batch: 160/401, elapsed_time:   286.0025s\n",
      "epoch:  4/ 5, batch: 180/401, elapsed_time:   290.5616s\n",
      "epoch:  4/ 5, batch: 200/401, elapsed_time:   294.2464s\n",
      "epoch:  4/ 5, batch: 220/401, elapsed_time:   297.9372s\n",
      "epoch:  4/ 5, batch: 240/401, elapsed_time:   302.0569s\n",
      "epoch:  4/ 5, batch: 260/401, elapsed_time:   305.7286s\n",
      "epoch:  4/ 5, batch: 280/401, elapsed_time:   309.9858s\n",
      "epoch:  4/ 5, batch: 300/401, elapsed_time:   314.1801s\n",
      "epoch:  4/ 5, batch: 320/401, elapsed_time:   317.9169s\n",
      "epoch:  4/ 5, batch: 340/401, elapsed_time:   322.0331s\n",
      "epoch:  4/ 5, batch: 360/401, elapsed_time:   326.6213s\n",
      "epoch:  4/ 5, batch: 380/401, elapsed_time:   330.5933s\n",
      "epoch:  4/ 5, batch: 400/401, elapsed_time:   334.6426s\n",
      "epoch:  4/ 5, average_loss_per_batch: 0.2744\n",
      "\n",
      "--------------------VALIDATION--------------------\n",
      "epoch:  4/ 5, batch:   5/32, elapsed_time:   335.5661s\n",
      "epoch:  4/ 5, batch:  10/32, elapsed_time:   336.3842s\n",
      "epoch:  4/ 5, batch:  15/32, elapsed_time:   337.2157s\n",
      "epoch:  4/ 5, batch:  20/32, elapsed_time:   338.0550s\n",
      "epoch:  4/ 5, batch:  25/32, elapsed_time:   338.9155s\n",
      "epoch:  4/ 5, batch:  30/32, elapsed_time:   339.8599s\n",
      "accuracy : 0.8355\n",
      "epoch:  4/ 5, average_loss_per_batch: 0.4098\n",
      "\n",
      "----------------------TRAIN-----------------------\n",
      "epoch:  5/ 5, batch:  20/401, elapsed_time:   343.8442s\n",
      "epoch:  5/ 5, batch:  40/401, elapsed_time:   347.4947s\n",
      "epoch:  5/ 5, batch:  60/401, elapsed_time:   351.3683s\n",
      "epoch:  5/ 5, batch:  80/401, elapsed_time:   355.0373s\n",
      "epoch:  5/ 5, batch: 100/401, elapsed_time:   359.1963s\n",
      "epoch:  5/ 5, batch: 120/401, elapsed_time:   363.3577s\n",
      "epoch:  5/ 5, batch: 140/401, elapsed_time:   367.0433s\n",
      "epoch:  5/ 5, batch: 160/401, elapsed_time:   370.9839s\n",
      "epoch:  5/ 5, batch: 180/401, elapsed_time:   374.9802s\n",
      "epoch:  5/ 5, batch: 200/401, elapsed_time:   379.0927s\n",
      "epoch:  5/ 5, batch: 220/401, elapsed_time:   383.0287s\n",
      "epoch:  5/ 5, batch: 240/401, elapsed_time:   386.7509s\n",
      "epoch:  5/ 5, batch: 260/401, elapsed_time:   390.7212s\n",
      "epoch:  5/ 5, batch: 280/401, elapsed_time:   395.5473s\n",
      "epoch:  5/ 5, batch: 300/401, elapsed_time:   399.2372s\n",
      "epoch:  5/ 5, batch: 320/401, elapsed_time:   403.4404s\n",
      "epoch:  5/ 5, batch: 340/401, elapsed_time:   407.3532s\n",
      "epoch:  5/ 5, batch: 360/401, elapsed_time:   411.0060s\n",
      "epoch:  5/ 5, batch: 380/401, elapsed_time:   414.8122s\n",
      "epoch:  5/ 5, batch: 400/401, elapsed_time:   418.8453s\n",
      "epoch:  5/ 5, average_loss_per_batch: 0.2456\n",
      "\n",
      "--------------------VALIDATION--------------------\n",
      "epoch:  5/ 5, batch:   5/32, elapsed_time:   419.7676s\n",
      "epoch:  5/ 5, batch:  10/32, elapsed_time:   420.5886s\n",
      "epoch:  5/ 5, batch:  15/32, elapsed_time:   421.4144s\n",
      "epoch:  5/ 5, batch:  20/32, elapsed_time:   422.2499s\n",
      "epoch:  5/ 5, batch:  25/32, elapsed_time:   423.0537s\n",
      "epoch:  5/ 5, batch:  30/32, elapsed_time:   423.8817s\n",
      "accuracy : 0.8565\n",
      "epoch:  5/ 5, average_loss_per_batch: 0.3694\n",
      "\n",
      "model parameters saved : acc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epoches = 5\n",
    "train_batch_num = len(train_data_loader)\n",
    "val_batch_num = len(val_data_loader)\n",
    "log_step = 200\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epoches):\n",
    "\n",
    "    print(\"{:-^50s}\".format(\"TRAIN\"))\n",
    "    encoder.train()\n",
    "    total_loss = 0\n",
    "    for i, (t1, t2, target) in enumerate(train_data_loader):\n",
    "\n",
    "        t1 = t1.to(device)\n",
    "        t2 = t2.to(device)\n",
    "        target = target.long().to(device)\n",
    "        \n",
    "        out = encoder(t1, t2)\n",
    "        loss = criterion(out, target)\n",
    "        encoder.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if (i+1) % log_step == 0:\n",
    "            print(f'epoch: {epoch+1:2d}/{num_epoches:2d}, batch: {i+1:3d}/{train_batch_num}, elapsed_time: {time.time()-start_time:10.4f}s')\n",
    "\n",
    "    print(f'epoch: {epoch+1:2d}/{num_epoches:2d}, average_loss_per_batch: {total_loss/train_batch_num:5.4f}\\n')\n",
    "\n",
    "    print(\"{:-^50s}\".format(\"VALIDATION\"))\n",
    "    encoder.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        out_list = []\n",
    "        target_list = []\n",
    "        for i, (t1, t2, target) in enumerate(val_data_loader):\n",
    "            \n",
    "            t1 = t1.to(device)\n",
    "            t2 = t2.to(device)\n",
    "            target = target.long().to(device)\n",
    "            \n",
    "            out = encoder(t1, t2)\n",
    "            loss = criterion(out, target)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            out_list.append(out.detach().cpu().numpy())\n",
    "            target_list.append(target.detach().cpu().numpy())\n",
    "\n",
    "            if (i+1) % (log_step//4) == 0:\n",
    "                print(f'epoch: {epoch+1:2d}/{num_epoches:2d}, batch: {i+1:3d}/{val_batch_num}, elapsed_time: {time.time()-start_time:10.4f}s')\n",
    "\n",
    "        out = np.concatenate(out_list, axis=0).argmax(1)\n",
    "        target = np.concatenate(target_list, axis=0)\n",
    "        acc = np.sum(out == target) / len(out)\n",
    "        print(f'accuracy : {acc:.4f}')\n",
    "        \n",
    "        print(f'epoch: {epoch+1:2d}/{num_epoches:2d}, average_loss_per_batch: {total_loss/val_batch_num:5.4f}\\n')\n",
    "\n",
    "        if total_loss/val_batch_num < min_loss:\n",
    "            min_loss = total_loss/val_batch_num\n",
    "            torch.save(encoder.state_dict(), './parameters/gru_mp_loss.pt')\n",
    "            print(\"model parameters saved : loss\\n\")\n",
    "\n",
    "        if acc > max_acc:\n",
    "            max_acc = acc\n",
    "            torch.save(encoder.state_dict(), './parameters/gru_mp_acc.pt')\n",
    "            print(\"model parameters saved : acc\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dde368ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoder.load_state_dict(torch.load('./parameters/gru_mp_loss.pt'))\n",
    "# encoder.load_state_dict(torch.load('./parameters/gru_mp_acc.pt'))\n",
    "encoder.load_state_dict(torch.load('./parameters/gru_mp_best.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "00fa2d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_list_test = []\n",
    "target_list_test = []\n",
    "encoder.eval()\n",
    "\n",
    "for i, (t1, t2, target) in enumerate(test_data_loader):\n",
    "    \n",
    "    t1 = t1.to(device)\n",
    "    t2 = t2.to(device)\n",
    "    target = target.long().to(device)\n",
    "    \n",
    "    out = encoder(t1, t2)\n",
    "    \n",
    "    out_list_test.append(out.detach().cpu().numpy().argmax(1))\n",
    "    target_list_test.append(target.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "effcb756",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_test = np.concatenate(out_list_test, axis=0)\n",
    "target_test = np.concatenate(target_list_test, axis=0)\n",
    "predictions = out_test\n",
    "labels = target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4db18496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8165\n",
      "precision : 0.7641\n",
      "recall : 0.7571\n",
      "F1 score : 0.7606\n",
      "TP :  583  FN :  187\n",
      "FP :  180  TN : 1050\n"
     ]
    }
   ],
   "source": [
    "print_test_statistics(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67fba5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71aa7547",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

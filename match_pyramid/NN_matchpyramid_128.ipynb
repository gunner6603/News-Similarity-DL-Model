{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a57acf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.path.abspath('')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3635f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from utils_ import *\n",
    "from mp_models import *\n",
    "from datasets import *\n",
    "from gensim import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc448a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_doc_list1_path = '../tmp_files/train_val_doc_list1.pkl'\n",
    "train_val_doc_list2_path = '../tmp_files/train_val_doc_list2.pkl'\n",
    "test_doc_list1_path = '../tmp_files/test_doc_list1.pkl'\n",
    "test_doc_list2_path = '../tmp_files/test_doc_list2.pkl'\n",
    "train_label_path = \"../dataset/newssim-train/label.txt\"\n",
    "test_label_path =  \"../dataset/newssim-test/label.txt\"\n",
    "vocab_path = '../tmp_files/vocab.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d6abaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_val_doc_list1_path, 'rb') as f:\n",
    "    train_val_doc_list1 = pickle.load(f)\n",
    "with open(train_val_doc_list2_path, 'rb') as f:\n",
    "    train_val_doc_list2 = pickle.load(f)\n",
    "with open(test_doc_list1_path, 'rb') as f:\n",
    "    test_doc_list1 = pickle.load(f)\n",
    "with open(test_doc_list2_path, 'rb') as f:\n",
    "    test_doc_list2 = pickle.load(f)\n",
    "with open(vocab_path, 'rb') as f:\n",
    "    vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "628be4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_num = 2000\n",
    "np.random.seed(3)\n",
    "indices = np.random.permutation(len(train_val_doc_list1))\n",
    "train_idx = indices[:-val_data_num]\n",
    "val_idx = indices[-val_data_num:]\n",
    "\n",
    "train_doc_list1 = []\n",
    "train_doc_list2 = []\n",
    "val_doc_list1 = []\n",
    "val_doc_list2 = []\n",
    "\n",
    "for idx in train_idx:\n",
    "    train_doc_list1.append(train_val_doc_list1[idx])\n",
    "    train_doc_list2.append(train_val_doc_list2[idx])\n",
    "\n",
    "for idx in val_idx:\n",
    "    val_doc_list1.append(train_val_doc_list1[idx])\n",
    "    val_doc_list2.append(train_val_doc_list2[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2258f7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25627 2000 2000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_doc_list1), len(val_doc_list1), len(test_doc_list1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d06cca90",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = get_labels(train_label_path)[train_idx]\n",
    "val_labels = get_labels(train_label_path)[val_idx]\n",
    "test_labels = get_labels(test_label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e303b65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25627 2000 2000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_labels), len(val_labels), len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f62dcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average document length : 24.78\n",
      "average sentence length : 14.06\n",
      "max document length : 844\n",
      "max sentence length : 204\n"
     ]
    }
   ],
   "source": [
    "max_doc_len = 0\n",
    "max_sent_len = 0\n",
    "total_list_len = 0\n",
    "total_doc_len = 0\n",
    "total_sent_len = 0\n",
    "for doc_list in [train_doc_list1, train_doc_list2, val_doc_list1, val_doc_list2]:\n",
    "    total_list_len += len(doc_list)\n",
    "    for doc in doc_list:\n",
    "        max_doc_len = max(max_doc_len, len(doc))\n",
    "        total_doc_len += len(doc)\n",
    "        for sent in doc:\n",
    "            max_sent_len = max(max_sent_len, len(sent))\n",
    "            total_sent_len += len(sent)\n",
    "print(f'average document length : {total_doc_len/total_list_len:0.2f}\\naverage sentence length : {total_sent_len/total_doc_len:0.2f}')\n",
    "print(f'max document length : {max_doc_len}\\nmax sentence length : {max_sent_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e23e0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_document_length = 32 # dummy variable\n",
    "max_sentence_length = 50 # dummy variable\n",
    "first_n_words = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df62e2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = NewsDataset(train_doc_list1, train_doc_list2, train_labels, vocab, max_document_length, max_sentence_length, first_n_words)\n",
    "val_data = NewsDataset(val_doc_list1, val_doc_list2, val_labels, vocab, max_document_length, max_sentence_length, first_n_words)\n",
    "test_data = NewsDataset(test_doc_list1, test_doc_list2, test_labels, vocab, max_document_length, max_sentence_length, first_n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7138b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "279f79f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_data_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "test_data_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4eb62d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51053"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a7a251b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embed_dim = 256\n",
    "pad_idx = vocab('<pad>')\n",
    "hidden_dim_gru = 100\n",
    "num_layers_gru = 1\n",
    "conv_sizes = [[5,5,8], [3,3,16]] # [[3,3,8], [3,3,16], [3,3,32]]\n",
    "pool_sizes = [[64,64], [16,16]] # [[110,110], [26,26], [5,5]]\n",
    "mp_hidden_dim = 256\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ffd933ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = MPEncoder2(vocab_size, embed_dim, pad_idx, hidden_dim_gru, num_layers_gru, conv_sizes, pool_sizes, mp_hidden_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "45a06e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = models.Word2Vec.load('../tmp_files/word2vec_256d.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1bf63ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_word_vectors = np.zeros((vocab_size, embed_dim))\n",
    "for i in range(2, vocab_size):\n",
    "    pretrained_word_vectors[i] = word2vec_model.wv[vocab.idx2word[i]]\n",
    "pretrained_word_vectors_torch = torch.FloatTensor(pretrained_word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "add43efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.embed.weight = nn.Parameter(pretrained_word_vectors_torch)\n",
    "encoder.embed.weight.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4569ad51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): MPEncoder2(\n",
       "    (embed): Embedding(51053, 256, padding_idx=0)\n",
       "    (gru): GRU(256, 100, batch_first=True, bidirectional=True)\n",
       "    (match_pyramid): MatchPyramid(\n",
       "      (conv): ModuleList(\n",
       "        (0): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1))\n",
       "        (1): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "      )\n",
       "      (bn): ModuleList(\n",
       "        (0): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (pool): ModuleList(\n",
       "        (0): AdaptiveAvgPool2d(output_size=(64, 64))\n",
       "        (1): AdaptiveAvgPool2d(output_size=(16, 16))\n",
       "      )\n",
       "      (linear1): Linear(in_features=4096, out_features=256, bias=True)\n",
       "      (linear2): Linear(in_features=256, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.device_count() > 1:\n",
    "    encoder = nn.DataParallel(encoder)\n",
    "encoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ec54e968",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss = 10000\n",
    "max_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "aac8e699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------TRAIN-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gunner6603/project1/data/anaconda3/envs/newvenv/lib/python3.9/site-packages/torch/nn/modules/rnn.py:849: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  ../aten/src/ATen/native/cudnn/RNN.cpp:925.)\n",
      "  result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1/ 5, batch: 200/801, elapsed_time:     6.1995s\n",
      "epoch:  1/ 5, batch: 400/801, elapsed_time:    12.3622s\n",
      "epoch:  1/ 5, batch: 600/801, elapsed_time:    18.5005s\n",
      "epoch:  1/ 5, batch: 800/801, elapsed_time:    24.5694s\n",
      "epoch:  1/ 5, average_loss_per_batch: 0.4375\n",
      "\n",
      "--------------------VALIDATION--------------------\n",
      "epoch:  1/ 5, batch:  50/63, elapsed_time:    25.3167s\n",
      "accuracy : 0.8145\n",
      "epoch:  1/ 5, average_loss_per_batch: 0.4025\n",
      "\n",
      "model parameters saved : loss\n",
      "\n",
      "model parameters saved : acc\n",
      "\n",
      "----------------------TRAIN-----------------------\n",
      "epoch:  2/ 5, batch: 200/801, elapsed_time:    31.8915s\n",
      "epoch:  2/ 5, batch: 400/801, elapsed_time:    38.0454s\n",
      "epoch:  2/ 5, batch: 600/801, elapsed_time:    43.8891s\n",
      "epoch:  2/ 5, batch: 800/801, elapsed_time:    49.7974s\n",
      "epoch:  2/ 5, average_loss_per_batch: 0.3547\n",
      "\n",
      "--------------------VALIDATION--------------------\n",
      "epoch:  2/ 5, batch:  50/63, elapsed_time:    50.5199s\n",
      "accuracy : 0.8435\n",
      "epoch:  2/ 5, average_loss_per_batch: 0.3531\n",
      "\n",
      "model parameters saved : loss\n",
      "\n",
      "model parameters saved : acc\n",
      "\n",
      "----------------------TRAIN-----------------------\n",
      "epoch:  3/ 5, batch: 200/801, elapsed_time:    56.9396s\n",
      "epoch:  3/ 5, batch: 400/801, elapsed_time:    62.9017s\n",
      "epoch:  3/ 5, batch: 600/801, elapsed_time:    68.9717s\n",
      "epoch:  3/ 5, batch: 800/801, elapsed_time:    75.0118s\n",
      "epoch:  3/ 5, average_loss_per_batch: 0.3036\n",
      "\n",
      "--------------------VALIDATION--------------------\n",
      "epoch:  3/ 5, batch:  50/63, elapsed_time:    75.7113s\n",
      "accuracy : 0.8430\n",
      "epoch:  3/ 5, average_loss_per_batch: 0.3604\n",
      "\n",
      "----------------------TRAIN-----------------------\n",
      "epoch:  4/ 5, batch: 200/801, elapsed_time:    82.0411s\n",
      "epoch:  4/ 5, batch: 400/801, elapsed_time:    87.9789s\n",
      "epoch:  4/ 5, batch: 600/801, elapsed_time:    94.0773s\n",
      "epoch:  4/ 5, batch: 800/801, elapsed_time:   100.1990s\n",
      "epoch:  4/ 5, average_loss_per_batch: 0.2541\n",
      "\n",
      "--------------------VALIDATION--------------------\n",
      "epoch:  4/ 5, batch:  50/63, elapsed_time:   100.9049s\n",
      "accuracy : 0.8400\n",
      "epoch:  4/ 5, average_loss_per_batch: 0.3694\n",
      "\n",
      "----------------------TRAIN-----------------------\n",
      "epoch:  5/ 5, batch: 200/801, elapsed_time:   107.2775s\n",
      "epoch:  5/ 5, batch: 400/801, elapsed_time:   113.2415s\n",
      "epoch:  5/ 5, batch: 600/801, elapsed_time:   119.2831s\n",
      "epoch:  5/ 5, batch: 800/801, elapsed_time:   125.2824s\n",
      "epoch:  5/ 5, average_loss_per_batch: 0.1942\n",
      "\n",
      "--------------------VALIDATION--------------------\n",
      "epoch:  5/ 5, batch:  50/63, elapsed_time:   125.9812s\n",
      "accuracy : 0.8375\n",
      "epoch:  5/ 5, average_loss_per_batch: 0.4201\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epoches = 5\n",
    "train_batch_num = len(train_data_loader)\n",
    "val_batch_num = len(val_data_loader)\n",
    "log_step = 200\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epoches):\n",
    "\n",
    "    print(\"{:-^50s}\".format(\"TRAIN\"))\n",
    "    encoder.train()\n",
    "    total_loss = 0\n",
    "    for i, (t1, t2, target) in enumerate(train_data_loader):\n",
    "\n",
    "        t1 = t1.to(device)\n",
    "        t2 = t2.to(device)\n",
    "        target = target.long().to(device)\n",
    "        \n",
    "        out = encoder(t1, t2)\n",
    "        loss = criterion(out, target)\n",
    "        encoder.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if (i+1) % log_step == 0:\n",
    "            print(f'epoch: {epoch+1:2d}/{num_epoches:2d}, batch: {i+1:3d}/{train_batch_num}, elapsed_time: {time.time()-start_time:10.4f}s')\n",
    "\n",
    "    print(f'epoch: {epoch+1:2d}/{num_epoches:2d}, average_loss_per_batch: {total_loss/train_batch_num:5.4f}\\n')\n",
    "\n",
    "    print(\"{:-^50s}\".format(\"VALIDATION\"))\n",
    "    encoder.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        out_list = []\n",
    "        target_list = []\n",
    "        for i, (t1, t2, target) in enumerate(val_data_loader):\n",
    "\n",
    "            t1 = t1.to(device)\n",
    "            t2 = t2.to(device)\n",
    "            target = target.long().to(device)\n",
    "            \n",
    "            out = encoder(t1, t2)\n",
    "            loss = criterion(out, target)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            out_list.append(out.detach().cpu().numpy())\n",
    "            target_list.append(target.detach().cpu().numpy())\n",
    "\n",
    "            if (i+1) % (log_step//4) == 0:\n",
    "                print(f'epoch: {epoch+1:2d}/{num_epoches:2d}, batch: {i+1:3d}/{val_batch_num}, elapsed_time: {time.time()-start_time:10.4f}s')\n",
    "\n",
    "        out = np.concatenate(out_list, axis=0).argmax(1)\n",
    "        target = np.concatenate(target_list, axis=0)\n",
    "        acc = np.sum(out == target) / len(out)\n",
    "        print(f'accuracy : {acc:.4f}')\n",
    "        \n",
    "        print(f'epoch: {epoch+1:2d}/{num_epoches:2d}, average_loss_per_batch: {total_loss/val_batch_num:5.4f}\\n')\n",
    "\n",
    "        if total_loss/val_batch_num < min_loss:\n",
    "            min_loss = total_loss/val_batch_num\n",
    "            torch.save(encoder.state_dict(), './parameters/mp_first_128_loss.pt')\n",
    "            print(\"model parameters saved : loss\\n\")\n",
    "\n",
    "        if acc > max_acc:\n",
    "            max_acc = acc\n",
    "            torch.save(encoder.state_dict(), './parameters/mp_first_128_acc.pt')\n",
    "            print(\"model parameters saved : acc\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dde368ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoder.load_state_dict(torch.load('./parameters/mp_first_128_loss.pt'))\n",
    "# encoder.load_state_dict(torch.load('./parameters/mp_first_128_acc.pt'))\n",
    "encoder.load_state_dict(torch.load('./parameters/mp_first_128_best.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "00fa2d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_list_test = []\n",
    "target_list_test = []\n",
    "encoder.eval()\n",
    "\n",
    "for i, (t1, t2, target) in enumerate(test_data_loader):\n",
    "    \n",
    "    t1 = t1.to(device)\n",
    "    t2 = t2.to(device)\n",
    "    target = target.long().to(device)\n",
    "    \n",
    "    out = encoder(t1, t2)\n",
    "    \n",
    "    out_list_test.append(out.detach().cpu().numpy().argmax(1))\n",
    "    target_list_test.append(target.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "effcb756",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_test = np.concatenate(out_list_test, axis=0)\n",
    "target_test = np.concatenate(target_list_test, axis=0)\n",
    "predictions = out_test\n",
    "labels = target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4db18496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8280\n",
      "precision : 0.7731\n",
      "recall : 0.7831\n",
      "F1 score : 0.7781\n",
      "TP :  603  FN :  167\n",
      "FP :  177  TN : 1053\n"
     ]
    }
   ],
   "source": [
    "print_test_statistics(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2ddf36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a8af31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
